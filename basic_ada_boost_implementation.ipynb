{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost Algorithm \n",
    "\n",
    "#### 1. Initialize weights $w_{i}=(1/N)$ (Assign each training point equal weights.)\n",
    "#### 2. Calculate error rate for each $'h'$ (classifier) \n",
    "$\\mathcal{E} = \\sum_{wrong} w_{i}$\n",
    "#### 3. Pick \"best\" h (classifier) with smallest error Or choose classifier which has error rate furthest from $1/2$ i.e.\n",
    "$max |\\mathcal{E} - \\frac{1}{2}|$\n",
    "#### 4. Calculate votting power for 'h'\n",
    "$\\alpha = \\frac{1}{2} ln \\frac{1-\\mathcal{E}}{\\mathcal{E}}$\n",
    "#### 5. Are we finished ? \n",
    "Is 'H' (Overall classifier) is good enough ?\n",
    "Enough Rounds ?\n",
    "No good classifier left ? (best 'h' has $\\mathcal{E} = 1/2$)\n",
    "#### 6. If No: \n",
    "Update weights to emphasize points that were misclassified.\n",
    "$w_{new} = \\begin{cases} \\frac{1}{2}\\frac{1}{1-\\mathcal{E}}w_{old} \\quad \\text{if right} \\\\  \\frac{1}{2}\\frac{1}{\\mathcal{E}}w_{old} \\quad \\text{if wrong}\\end{cases}$\n",
    "</br>Go to step 2 and repeat.\n",
    "#### 7. If Yes:\n",
    "The Overall classsifier is 'H(x)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifiers:\n",
    "    \"\"\"dummy classifier which can be replaced with actual classifiers.\"\"\"\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.Y_predict = []\n",
    "        \n",
    "    def classifier_one(self):\n",
    "        labels = []\n",
    "        for each_data_point in X:\n",
    "            if each_data_point[0] < 2:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "        return labels\n",
    "    \n",
    "    def classifier_one_predict(self, x):\n",
    "        if x[0] < 2:\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def classifier_two(self):\n",
    "        labels = []\n",
    "        for each_data_point in X:\n",
    "            if each_data_point[0] < 4:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "        return labels\n",
    "    \n",
    "    def classifier_two_predict(self, x):\n",
    "        if x[0] < 4:\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def classifier_three(self):\n",
    "        labels = []\n",
    "        for each_data_point in X:\n",
    "            if each_data_point[0] < 6:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "        return labels\n",
    "    \n",
    "    def classifier_three_predict(self, x):\n",
    "        if x[0] < 6:\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def classifier_four(self):\n",
    "        labels = []\n",
    "        for each_data_point in X:\n",
    "            if each_data_point[0] > 2:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "        return labels \n",
    "    \n",
    "    def classifier_four_predict(self, x):\n",
    "        if x[0] > 2:\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def classifier_five(self):\n",
    "        labels = []\n",
    "        for each_data_point in X:\n",
    "            if each_data_point[0] > 4:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "        return labels\n",
    "    \n",
    "    def classifier_five_predict(self, x):\n",
    "        if x[0] > 4:\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def classifier_six(self):\n",
    "        labels = []\n",
    "        for each_data_point in X:\n",
    "            if each_data_point[0] > 6:\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(-1)\n",
    "        return labels \n",
    "    \n",
    "    def classifier_six_predict(self, x):\n",
    "        if x[0] > 6:\n",
    "            return 1 \n",
    "        else:\n",
    "            return -1\n",
    "    \n",
    "    def misclassified_points(self, Y_predict):\n",
    "        Y = np.array(self.Y)\n",
    "        Y_predict = np.array(Y_predict)\n",
    "        #import pdb; pdb.set_trace()\n",
    "        index_ = np.where(Y != Y_predict)\n",
    "        return X[index_], index_\n",
    "    \n",
    "    def classify_using_all(self):\n",
    "        classifiers = [('classifier_one', self.classifier_one()),\n",
    "                       ('classifier_two', self.classifier_two()),\n",
    "                       ('classifier_three', self.classifier_three()),\n",
    "                       ('classifier_four', self.classifier_four()),\n",
    "                       ('classifier_five', self.classifier_five()),\n",
    "                       ('classifier_six', self.classifier_six())]\n",
    "        classifier_misclassified_point = []\n",
    "        classifier_misclassified_pt_ind = []\n",
    "        classifier_index = 0 \n",
    "        for name, each_classifier in classifiers:\n",
    "            labels = each_classifier\n",
    "            points, index_ = self.misclassified_points(labels)\n",
    "            classifier_misclassified_point.append(points)\n",
    "            classifier_misclassified_pt_ind.extend(index_)\n",
    "        return np.array(classifier_misclassified_point), classifier_misclassified_pt_ind\n",
    "    \n",
    "# data_set  \n",
    "X = np.array([[1, 5], [5, 5], [3, 3], [1, 1], [5,1]])\n",
    "Y = np.array([1, 1, -1, 1, 1])\n",
    "\n",
    "\n",
    "class Adaboost_imp(Classifiers):\n",
    "    \"\"\"Adaboost algo\"\"\"\n",
    "    def __init__(self, X, Y, max_iter=5):\n",
    "        super().__init__(X, Y)\n",
    "        self.X = X\n",
    "        self.Y = Y \n",
    "        self.classifiers_mis_points, self.classifier_misclassified_pt_ind = self.classify_using_all()\n",
    "        self.error_rate = np.zeros(self.classifiers_mis_points.shape)\n",
    "        self.weights = np.zeros((len(self.X), ))\n",
    "        #self.weight_new = np.zeros((len(self.X), 1))\n",
    "        self.classifiers_count = len(self.classifiers_mis_points)\n",
    "        self.best_classifier = None\n",
    "        self.max_iter = max_iter\n",
    "        self.alphas = [0]*self.classifiers_count\n",
    "        self.classifiers = {0: self.classifier_one_predict, 1: self.classifier_two_predict,\n",
    "                           2: self.classifier_three_predict, 3: self.classifier_four_predict,\n",
    "                           4: self.classifier_five_predict}\n",
    "        \n",
    "    def overall_classifier(self, x):\n",
    "        total = 0\n",
    "        for clas, each_alpha in enumerate(self.alphas):\n",
    "            if each_alpha:\n",
    "                total += each_alpha * self.classifiers[clas](x)\n",
    "        return np.sign(total)\n",
    "    \n",
    "    def initialize_weight(self):\n",
    "        self.weights[:] = 1 / len(self.X) \n",
    "        \n",
    "        print(\"initial weights %s\" %self.weights)\n",
    "    \n",
    "    def error_rate_(self):\n",
    "        \n",
    "        for each_clas in range(self.classifiers_count):\n",
    "            self.error_rate[each_clas] = sum(self.weights[self.classifier_misclassified_pt_ind[each_clas]])\n",
    "        \n",
    "        print(\"error_rate %s\" %self.error_rate)\n",
    "    \n",
    "    def pick_best_classifier(self, based_on_smallest_error=False):\n",
    "        if based_on_smallest_error:\n",
    "            self.best_classifier = np.argsort(self.error_rate)[0]\n",
    "        # todo self.classifier_misclassified_pt_ind\n",
    "    \n",
    "    def votting_power(self):\n",
    "        self.alphas[self.best_classifier] = 0.5 * math.log((1 - self.error_rate[self.best_classifier]) / self.error_rate[self.best_classifier])\n",
    "        \n",
    "    \n",
    "    def is_finished(self):\n",
    "        if self.error_rate[self.best_classifier] == 0.5:\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def update_weights(self):\n",
    "        weight_new = [0]*len(self.weights)\n",
    "        # misclassified pts \n",
    "        for pt_ind, pt in enumerate(self.X):\n",
    "            if pt_ind not in self.classifier_misclassified_pt_ind[self.best_classifier]:\n",
    "                weight_new[pt_ind] = 0.5 * (1/ (1 - self.error_rate[self.best_classifier])) * self.weights[pt_ind]\n",
    "            else:\n",
    "                weight_new[pt_ind] = 0.5 * (1/ (self.error_rate[self.best_classifier])) * self.weights[pt_ind]\n",
    "        \n",
    "        self.weights = np.array(weight_new)\n",
    "        print(\"weight new %s\" %self.weights)\n",
    "        \n",
    "    def algo(self):\n",
    "        self.initialize_weight()\n",
    "        for iter_ in range(self.max_iter):\n",
    "            self.error_rate_()\n",
    "            self.pick_best_classifier(based_on_smallest_error=True)\n",
    "            self.votting_power()\n",
    "            if self.is_finished(): break\n",
    "            self.update_weights() \n",
    "\n",
    "    \n",
    "ada_boost = Adaboost_imp(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial weights [0.2 0.2 0.2 0.2 0.2]\n",
      "error_rate [0.4 0.6 0.2 0.6 0.4 0.8]\n",
      "weight new [0.125 0.125 0.5   0.125 0.125]\n",
      "error_rate [0.25 0.75 0.5  0.75 0.25 0.5 ]\n",
      "weight new [0.08333333 0.25       0.33333333 0.08333333 0.25      ]\n",
      "error_rate [0.5        0.83333333 0.33333333 0.5        0.16666667 0.66666667]\n",
      "weight new [0.25 0.15 0.2  0.25 0.15]\n",
      "error_rate [0.3 0.5 0.2 0.7 0.5 0.8]\n",
      "weight new [0.15625 0.09375 0.5     0.15625 0.09375]\n",
      "error_rate [0.1875 0.6875 0.5    0.8125 0.3125 0.5   ]\n",
      "weight new [0.09615385 0.25       0.30769231 0.09615385 0.25      ]\n"
     ]
    }
   ],
   "source": [
    "ada_boost.algo()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_boost.overall_classifier([3, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n",
    "1. Boosting (Adaboost) by Jessica Noss MIT [link](https://www.youtube.com/watch?v=gmok1h8wG-Q)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
